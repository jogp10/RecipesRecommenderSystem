{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hummus - Community Based Recommendations**\n",
    "Notebook for the first project for the Machine Learning Complements course (CAC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils as ut\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import networkx as nx\n",
    "import os\n",
    "from networkx.algorithms.community import greedy_modularity_communities, girvan_newman, label_propagation_communities\n",
    "import matplotlib.pyplot as plt\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Dataset, Reader, KNNBasic, NormalPredictor, SVD, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = True\n",
    "SAMPLES = 10000\n",
    "USE_SAMPLES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SAMPLES:\n",
    "    df_members = pd.read_csv('pp_members_sampled.csv')\n",
    "    df_recipes = pd.read_csv('pp_recipes_sampled.csv')\n",
    "    df_reviews = pd.read_csv('pp_reviews_sampled.csv')\n",
    "else:\n",
    "    df_members = pd.read_csv('pp_members.csv')#, nrows=SAMPLES)\n",
    "    df_recipes = pd.read_csv('pp_recipes.csv')#, nrows=SAMPLES)\n",
    "    df_reviews = pd.read_csv('pp_reviews.csv', nrows=SAMPLES)\n",
    "\n",
    "    df_members = df_members[df_members['member_id'].isin(df_reviews['member_id'])] # keep only members who have reviewed\n",
    "    df_recipes = df_recipes[df_recipes['recipe_id'].isin(df_reviews['recipe_id'])] # keep only recipes that have been reviewed\n",
    "    \n",
    "    # Save the sampled data\n",
    "    df_members.to_csv('pp_members_sampled.csv', index=False)\n",
    "    df_recipes.to_csv('pp_recipes_sampled.csv', index=False)\n",
    "    df_reviews.to_csv('pp_reviews_sampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observation - Members dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.initial_obs(df_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_members.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observation - Recipes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.initial_obs(df_recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observation - Reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.initial_obs(df_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot amount of reviews over rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.plot_reviews_rating(df_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot amount of users over amount of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.plot_num_users_num_reviews(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average rating for each recipe\n",
    "# Filter recipes with more than 20 reviews\n",
    "filtered_recipes = df_recipes[df_recipes['number_of_ratings'] > 20]\n",
    "\n",
    "# Sort recipes based on average rating\n",
    "top_rated_recipes = filtered_recipes.sort_values(by='average_rating', ascending=False).head(10)\n",
    "\n",
    "# Print the name and rating of the top-rated recipes as well as the number of reviews\n",
    "print('Top-Rated Recipes:')\n",
    "print('------------------')\n",
    "\n",
    "for index, recipe in top_rated_recipes.iterrows():\n",
    "    print(f\"{recipe['title']} (Recipe ID: {recipe['recipe_id']}) - Average Rating: {recipe['average_rating']:.2f} ({recipe['number_of_ratings']} reviews)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Preparation - Create the graph for network analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a graph with the members as nodes and the reviews as edges. The weight of the edges will be the number of reviews in common (to the same recipe with the same attitude) between the two members. This will allow us to use network analysis to find communities of members with similar tastes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will group the reviews by recipe and evaluations, so we can extract the members that have something in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group reviews by recipe and evaluation (>3, <=3)\n",
    "grouped_reviews = df_reviews.groupby(['recipe_id', df_reviews['rating'] > 3])\n",
    "\n",
    "# Create a dictionary to store relations between users\n",
    "user_relations = {}\n",
    "\n",
    "# Iterate through each group\n",
    "for (recipe_id, is_positive_rating), group in grouped_reviews:\n",
    "    # Extract user IDs for this recipe and evaluation\n",
    "    if VERBOSE: print(recipe_id, is_positive_rating, group['member_id'].unique())\n",
    "    user_ids = group['member_id'].unique()\n",
    "    user_ids.sort()\n",
    "    \n",
    "    # Update relations between users for this recipe\n",
    "    for i, user_id1 in enumerate(user_ids):\n",
    "        for user_id2 in user_ids[i+1:]:\n",
    "            # Check if there's an entry for this relation between users\n",
    "            if (user_id1, user_id2) not in user_relations:\n",
    "                if VERBOSE: print(f\"Creating new relation between {user_id1} and {user_id2}\")\n",
    "                user_relations[(user_id1, user_id2)] = 0\n",
    "            \n",
    "            # Increment the relation count between the users based on the evaluation\n",
    "            user_relations[(user_id1, user_id2)] += 1\n",
    "            if VERBOSE: print(f\"Relation between {user_id1} and {user_id2} has been incremented to {user_relations[(user_id1, user_id2)]}\")\n",
    "\n",
    "# Now user_relations contains relations between users\n",
    "if VERBOSE: print(\"Size of user_relations:\", len(user_relations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users with the same taste will have a high number in the relation, and users with different tastes will have a low number. Here are the most strong relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = sorted(user_relations.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Print the 10 most frequent key-value pairs\n",
    "for key, value in sorted_dict[:10]:\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the graph..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "vertex_indices = {}\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists('graph_file.graphml'):\n",
    "    # Load the graph from file\n",
    "    if VERBOSE: print(\"Loading graph from file\")\n",
    "    g = nx.read_graphml('graph_file.graphml')\n",
    "else:\n",
    "    if VERBOSE: print(\"Creating new graph\")\n",
    "    for (u,v), weight in user_relations.items():\n",
    "        g.add_edge(u, v, weight = weight)\n",
    "    nx.write_graphml(g, \"graph_file.graphml\")\n",
    "    \n",
    "if VERBOSE: print(g)\n",
    "nx.draw(g, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Network Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes:\", g.number_of_nodes())\n",
    "print(\"Number of edges:\", g.number_of_edges())\n",
    "print(\"Average degree:\", sum(dict(g.degree()).values()) / g.number_of_nodes())\n",
    "print(\"Graph density:\", nx.density(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph itself is very sparse as the density is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Law Distribution\n",
    "Here, we will investigate whether our network adheres to a power law distribution, which signifies a characteristic pattern in which a few nodes possess an exceptionally high number of connections, while the majority have only a few connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = sorted([d for n, d in g.degree()], reverse=True)\n",
    "degree_count = np.unique(degree_sequence, return_counts=True)\n",
    "\n",
    "# Plot degree distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(degree_count[0], degree_count[1], marker='o', color='b', alpha=0.5)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title(\"Degree Distribution\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our network does follow a power law distribution. However, there are some outliers that might appear because we're only looking at a portion of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Influencial Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll employ various statistical measures to extract insights about our data, particularly focusing on identifying influential users. To achieve this, we will compute different centrality metrics including degree centrality, betweenness centrality, eigenvector centrality, PageRank and closeness centrality for the top 10 users in each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user with high degree centrality likely reviews a large number of recipes. They may be very active in providing feedback on various recipes, indicating a strong engagement with the platform or community. They might have a significant influence on others in the network, potentially influencing their choices of recipes for others to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMOUNT_USERS = 10\n",
    "\n",
    "degree_centrality = nx.degree_centrality(g)\n",
    "degree_centrality = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "degree_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in degree_centrality[0:5]])]\n",
    "degree_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closeness Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measure for finding the individuals who are best placed to influence the entire network most quickly, meaning the users that are \"close\" to all other users in the network in terms of the shortest paths between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closeness_centrality = nx.closeness_centrality(g, distance='weight')\n",
    "# closeness_centrality = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "# closeness_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in closeness_centrality[0:5]])]\n",
    "# closeness_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measure shows which users who are ‘bridges’ between other users in a network, it's good to find the individuals who influence the flow around a system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#betweenness_centrality = nx.betweenness_centrality(g, weight= 'weight')\n",
    "#betweenness_centrality = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "#betweenness_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in betweenness_centrality[0:5]])]\n",
    "#betweenness_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EigenVector Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigen_centrality = nx.eigenvector_centrality(g, weight='weight')\n",
    "# eigen_centrality = sorted(eigen_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "# eigen_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in eigen_centrality[0:5]])]\n",
    "# eigen_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_rank = nx.pagerank(g, weight='weight')\n",
    "page_rank = sorted(page_rank.items(), key=lambda x: x[1], reverse=True)\n",
    "page_rank_members = df_members[df_members['member_id'].isin([int(x[0]) for x in page_rank[0:5]])]\n",
    "page_rank_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Detection\n",
    "In this part we will test different community detection algorithms and run some metrics to find out which one is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Louvain Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_communities = greedy_modularity_communities(g)\n",
    "for i, community in enumerate(louvain_communities):\n",
    "    print(f\"Community {i + 1}: {len(community)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Propagation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_prop_communities = list(label_propagation_communities(g))\n",
    "label_prop_communities = sorted(label_prop_communities, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "for i, community in enumerate(label_prop_communities):\n",
    "    print(f\"Community {i + 1}: {len(community)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Filtering\n",
    "Here we will be removing the communities with very few users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average number of users in a community\n",
    "average_users = sum([len(x) for x in louvain_communities]) / len(louvain_communities)\n",
    "print(\"Average Amount Users p/ Community: \", average_users)\n",
    "\n",
    "filtered_communities = [c for c in louvain_communities if len(c) >= average_users]\n",
    "for i, community in enumerate(filtered_communities):\n",
    "    print(f\"Community {i + 1}: {len(community)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_rmse = {\"Random Recommender\":0, \"User-Based CF\":0, \"Item-Based CF\":0, \"Model-Based CF\":0, \"Content-Based Filtering\":0}\n",
    "communities_mae = {\"Random Recommender\":0, \"User-Based CF\":0, \"Item-Based CF\":0, \"Model-Based CF\":0, \"Content-Based Filtering\":0}\n",
    "communities_precision = {\"Random Recommender\":0, \"User-Based CF\":0, \"Item-Based CF\":0, \"Model-Based CF\":0, \"Content-Based Filtering\":0}\n",
    "communities_recall = {\"Random Recommender\":0, \"User-Based CF\":0, \"Item-Based CF\":0, \"Model-Based CF\":0, \"Content-Based Filtering\":0}\n",
    "whole_dataset_mae = {\"Random Recommender\":0, \"User-Based CF\":0, \"Item-Based CF\":0, \"Model-Based CF\":0, \"Content-Based Filtering\":0}\n",
    "whole_dataset_rmse = {\"Random Recommender\":0, \"User-Based CF\":0, \"Item-Based CF\":0, \"Model-Based CF\":0, \"Content-Based Filtering\":0}\n",
    "whole_dataset_precision = {\"Random Recommender\":0, \"User-Based CF\":0, \"Item-Based CF\":0, \"Model-Based CF\":0, \"Content-Based Filtering\":0}\n",
    "whole_dataset_recall = {\"Random Recommender\":0, \"User-Based CF\":0, \"Item-Based CF\":0, \"Model-Based CF\":0, \"Content-Based Filtering\":0}\n",
    "\n",
    "models_predictions = {}\n",
    "\n",
    "filtered_users = [int(user) for sublist in filtered_communities for user in sublist]\n",
    "\n",
    "df_members = df_members[df_members['member_id'].isin(filtered_users)]\n",
    "df_reviews = df_reviews[df_reviews['member_id'].isin(filtered_users)]\n",
    "df_recipes = df_recipes[df_recipes['recipe_id'].isin(df_reviews['recipe_id'])]\n",
    "\n",
    "print(\"Shape of Filtered Members:\", df_members.shape)\n",
    "print(\"Shape of Filtered Reviews:\", df_reviews.shape)\n",
    "print(\"Shape of Filtered Recipes\", df_recipes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering (Applied @ each community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll be exploring recommender systems that help suggest items based on similarities between users or items. We'll dive into both user-based and item-based collaborative filtering methods. Our aim is to apply these techniques to different communities, assess how well they work for each, and then gauge their overall performance by averaging the errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will predict a user's preferences based on the preferences of similar users (users in the same community)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rmse, avg_mae, avg_precision, avg_recall = ut.collaborative_filtering(df_reviews, filtered_communities, 0.25, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\033[1m-----Overall Performance-----\\033[0m\")\n",
    "print(f\"\\033[1mAverage RMSE ->\\033[0m\", avg_rmse)\n",
    "print(f\"\\033[1mAverage MAE ->\\033[0m\", avg_mae)\n",
    "print(f\"\\033[1mAverage Precision ->\\033[0m\", avg_precision)\n",
    "print(f\"\\033[1mAverage Recall ->\\033[0m\", avg_recall)\n",
    "print()    \n",
    "\n",
    "communities_rmse[\"User-Based CF\"] = avg_rmse\n",
    "communities_mae[\"User-Based CF\"] = avg_mae\n",
    "communities_precision[\"User-Based CF\"] = avg_precision\n",
    "communities_recall[\"User-Based CF\"] = avg_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Item-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we will use a recommendation approach that predicts a user's preferences by examining similarities between items rather than users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rmse, avg_mae, avg_precision, avg_recall = ut.collaborative_filtering(df_reviews, filtered_communities, 0.25, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\033[1m-----Overall Performance-----\\033[0m\")\n",
    "print(f\"\\033[1mAverage RMSE ->\\033[0m\", avg_rmse)\n",
    "print(f\"\\033[1mAverage MAE ->\\033[0m\", avg_mae)\n",
    "print(f\"\\033[1mAverage Precision ->\\033[0m\", avg_precision)\n",
    "print(f\"\\033[1mAverage Recall ->\\033[0m\", avg_recall)\n",
    "print()    \n",
    "\n",
    "communities_rmse[\"Item-Based CF\"] = avg_rmse\n",
    "communities_mae[\"Item-Based CF\"] = avg_mae\n",
    "communities_precision[\"Item-Based CF\"] = avg_precision\n",
    "communities_recall[\"Item-Based CF\"] = avg_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will employ model-based collaborative filtering for personalized recommendations, contrasting with memory-based methods. Unlike memory-based approaches that directly compare user-item interactions, model-based methods utilize mathematical models to capture underlying patterns and relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rmse, avg_mae, avg_precision, avg_recall = ut.collaborative_filtering(df_reviews, filtered_communities, 0.25, False, 'SVD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\033[1m-----Overall Performance-----\\033[0m\")\n",
    "print(f\"\\033[1mAverage RMSE ->\\033[0m\", avg_rmse)\n",
    "print(f\"\\033[1mAverage MAE ->\\033[0m\", avg_mae)\n",
    "print(f\"\\033[1mAverage Precision ->\\033[0m\", avg_precision)\n",
    "print(f\"\\033[1mAverage Recall ->\\033[0m\", avg_recall)\n",
    "print()    \n",
    "\n",
    "communities_rmse[\"Model-Based CF\"] = avg_rmse\n",
    "communities_mae[\"Model-Based CF\"] = avg_mae\n",
    "communities_precision[\"Model-Based CF\"] = avg_precision\n",
    "communities_recall[\"Model-Based CF\"] = avg_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content-based Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll be exploring recommender systems that suggest items based on similarities between the characteristics of items. We'll delve into content-based filtering methods, which recommend items to users based on the similarity of the items' features or attributes. Our aim is to apply these techniques to different communities, assess how well they work for each community, and then evaluate their overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By vectorizing text based features we can find similar recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recommendations = ut.find_similars(df_reviews, df_recipes, filtered_communities)\n",
    "\n",
    "for community_id, community_recommendations in all_recommendations.items():\n",
    "        print(f\"\\033[1mCommunity {community_id} Recommendations:\\033[0m\")\n",
    "        for recipe_id, recipe_data in community_recommendations.items():\n",
    "            print(f\"\\n\\033[1mOriginal Recipe: {recipe_data['original_title']} (Recipe ID: {recipe_id})\\033[0m\")\n",
    "            print(\"Similar Recipes:\")\n",
    "            unique_similar_recipe_ids = set()  # Track unique similar recipe IDs for each original recipe\n",
    "            for similar_recipe in recipe_data['similar_recipes']:\n",
    "                if similar_recipe['id'] not in unique_similar_recipe_ids:\n",
    "                    print(f\"- {similar_recipe['title']} (Recipe ID: {similar_recipe['id']}) | Similarity Score: {similar_recipe['score']:.2f}\")\n",
    "                    unique_similar_recipe_ids.add(similar_recipe['id'])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similar_recipes = ut.create_similar_recipes_dataframe(all_recommendations)\n",
    "print(df_similar_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rmse, avg_mae = ut.content_based_filtering(df_reviews, df_similar_recipes, filtered_communities, 0.25, False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, some communities have a RMSE and a MAE of 0. This happens because there is no recipe reviewed by a user that has a similar reviewed by the same user. For the sake of the average results integrety, results from these communities will be excluded from the overall calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\033[1m-----Overall Performance-----\\033[0m\")\n",
    "print(f\"\\033[1mAverage RMSE ->\\033[0m\", avg_rmse)\n",
    "print(f\"\\033[1mAverage MAE ->\\033[0m\", avg_mae)\n",
    "print()  \n",
    "\n",
    "communities_rmse[\"Content-Based Filtering\"] = avg_rmse\n",
    "communities_mae[\"Content-Based Filtering\"] = avg_mae\n",
    "communities_precision[\"Content-Based Filtering\"] = 0\n",
    "communities_recall[\"Content-Based Filtering\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity model (Naive Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popularity model\n",
    "#Sort by \"average_rating\" and numeber_of_ratings > 30\n",
    "df_recipes_top = df_recipes[df_recipes['number_of_ratings'] > 30]\n",
    "df_recipes_top = df_recipes_top.sort_values(by='average_rating', ascending=False)\n",
    "\n",
    "# Get top N recommendations\n",
    "top_n_popularity = df_recipes_top.head(10)\n",
    "\n",
    "# Print the top N recommended items\n",
    "print(\"\\nTop Recommendations using Popularity Model:\")\n",
    "for index, recipe in top_n_popularity.iterrows():\n",
    "    print(f\"ID: {recipe['recipe_id']}, Title: {recipe['title']}, Average Rating: {recipe['average_rating']:.2f}, Number of Ratings: {recipe['number_of_ratings']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_reviews[['member_id', 'recipe_id', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_algo = NormalPredictor()\n",
    "rmse, mae, predictions, precision, recall = ut.evaluate_model(random_algo, trainset, testset)\n",
    "print(f\"RMSE -> {rmse}\")\n",
    "print(f\"MAE -> {mae}\")\n",
    "print(f\"Precision -> {precision}\")\n",
    "print(f\"Recall -> {recall}\")\n",
    "\n",
    "whole_dataset_rmse[\"Random Recommender\"] = rmse\n",
    "whole_dataset_mae[\"Random Recommender\"] = mae\n",
    "whole_dataset_precision[\"Random Recommender\"] = precision\n",
    "whole_dataset_recall[\"Random Recommender\"] = recall\n",
    "models_predictions[\"Random Recommender\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run random for communities\n",
    "avg_rmse, avg_mae, avg_precision, avg_recall = ut.collaborative_filtering(df_reviews, filtered_communities, 0.25, True, 'Random')\n",
    "communities_rmse[\"Random Recommender\"] = avg_rmse\n",
    "communities_mae[\"Random Recommender\"] = avg_mae\n",
    "communities_precision[\"Random Recommender\"] = avg_precision\n",
    "communities_recall[\"Random Recommender\"] = avg_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering (Applied @ whole data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubcf_algo = KNNBasic(sim_options={'user_based': True})\n",
    "rmse, mae, pred_user, precision, recall = ut.evaluate_model(ubcf_algo, trainset, testset)\n",
    "print(f\"RMSE -> {rmse}\")\n",
    "print(f\"MAE -> {mae}\")\n",
    "print(f\"Precision -> {precision}\")\n",
    "print(f\"Recall -> {recall}\")\n",
    "\n",
    "whole_dataset_rmse[\"User-Based CF\"] = rmse\n",
    "whole_dataset_mae[\"User-Based CF\"] = mae\n",
    "whole_dataset_precision[\"User-Based CF\"] = precision\n",
    "whole_dataset_recall[\"User-Based CF\"] = recall\n",
    "models_predictions[\"User-Based CF\"] = pred_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Item-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibcf_algo = KNNBasic(sim_options={'user_based': False})\n",
    "rmse, mae, pred_item, precision, recall = ut.evaluate_model(ibcf_algo, trainset, testset)\n",
    "print(f\"RMSE -> {rmse}\")\n",
    "print(f\"MAE -> {mae}\")\n",
    "print(f\"Precision -> {precision}\")\n",
    "print(f\"Recall -> {recall}\")\n",
    "\n",
    "whole_dataset_rmse[\"Item-Based CF\"] = rmse\n",
    "whole_dataset_mae[\"Item-Based CF\"] = mae\n",
    "whole_dataset_precision[\"Item-Based CF\"] = precision\n",
    "whole_dataset_recall[\"Item-Based CF\"] = recall\n",
    "models_predictions[\"Item-Based CF\"] = pred_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_algo = SVD(verbose = False)\n",
    "rmse, mae, pred_model, precision, recall = ut.evaluate_model(ibcf_algo, trainset, testset)\n",
    "print(f\"RMSE -> {rmse}\")\n",
    "print(f\"MAE -> {mae}\")\n",
    "print(f\"Precision -> {precision}\")\n",
    "print(f\"Recall -> {recall}\")\n",
    "\n",
    "whole_dataset_rmse[\"Model-Based CF\"] = rmse\n",
    "whole_dataset_mae[\"Model-Based CF\"] = mae\n",
    "whole_dataset_precision[\"Model-Based CF\"] = precision\n",
    "whole_dataset_recall[\"Model-Based CF\"] = recall\n",
    "models_predictions[\"Model-Based CF\"] = pred_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE and MAE values for each model with communities and whole dataset\n",
    "# Models\n",
    "models = [\"Random Recommender\", \"User-Based CF\", \"Item-Based CF\",\n",
    "          \"Model-Based CF\", \"Content-Based Filtering\"]\n",
    "indices = np.arange(len(models))\n",
    "\n",
    "# RMSE and MAE values for each model with communities and whole dataset\n",
    "communities_rmse_values = [communities_rmse[model] for model in models]\n",
    "communities_mae_values = [communities_mae[model] for model in models]\n",
    "communities_precision_values = [communities_precision[model] for model in models]\n",
    "communities_recall_values = [communities_recall[model] for model in models]\n",
    "whole_dataset_rmse_values = [whole_dataset_rmse[model] for model in models]\n",
    "whole_dataset_mae_values = [whole_dataset_mae[model] for model in models]\n",
    "whole_dataset_precision_values = [whole_dataset_precision[model] for model in models]\n",
    "whole_dataset_recall_values = [whole_dataset_recall[model] for model in models]\n",
    "\n",
    "\n",
    "# Create subplots for RMSE and MAE values\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 10))\n",
    "\n",
    "# Plot RMSE values\n",
    "axes[0].bar(indices - 0.2, communities_rmse_values, width=0.4, color='lightsalmon', alpha=0.6, label='Communities RMSE')\n",
    "axes[0].bar(indices + 0.2, whole_dataset_rmse_values, width=0.4, color='wheat', alpha=0.6, label='Whole Dataset RMSE')\n",
    "axes[0].set_xticks(indices)\n",
    "axes[0].set_xticklabels(models, rotation=45)\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].set_title('Comparison of RMSE Values for Different Models')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[0].set_ylim(0, max(communities_rmse_values + whole_dataset_rmse_values) + 0.2)\n",
    "\n",
    "# Plot MAE values\n",
    "axes[1].bar(indices - 0.2, communities_mae_values, width=0.4, color='cornflowerblue', alpha=0.6, label='Communities MAE')\n",
    "axes[1].bar(indices + 0.2, whole_dataset_mae_values, width=0.4, color='seagreen', alpha=0.6, label='Whole Dataset MAE')\n",
    "axes[1].set_xticks(indices)\n",
    "axes[1].set_xticklabels(models, rotation=45)\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('Comparison of MAE Values for Different Models')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[1].set_ylim(0, max(communities_mae_values + whole_dataset_mae_values) + 0.2)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Models\n",
    "models = [\"Random Recommender\", \"User-Based CF\", \"Item-Based CF\", \"Model-Based CF\"]\n",
    "\n",
    "# Create subplots for error distribution\n",
    "fig, axes = plt.subplots(nrows=len(models), ncols=1, figsize=(10, 15))\n",
    "\n",
    "# Plot error distribution for each model\n",
    "for i, model in enumerate(models):\n",
    "    predictions = models_predictions[model]  # Get predictions for the current model\n",
    "    actual_ratings = [pred.r_ui for pred in predictions]  # Extract actual ratings\n",
    "    predicted_ratings = [pred.est for pred in predictions]  # Extract predicted ratings\n",
    "    errors = [abs(actual - predicted) for actual, predicted in zip(actual_ratings, predicted_ratings)]  # Compute errors\n",
    "    \n",
    "     # Plot the error distribution\n",
    "    hist, bins, _ = axes[i].hist(errors, bins=30, color='teal', alpha=0.6)\n",
    "    axes[i].set_title(f'Error Distribution for {model}')\n",
    "    axes[i].set_xlabel('Error')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    # Annotate bars with frequency values\n",
    "    a = 0\n",
    "    for rect, count in zip(hist, hist):\n",
    "\n",
    "        height = rect\n",
    "  \n",
    "        axes[i].text(bins[a]+0.06, height + 0.5, int(height), ha='center', va='bottom')\n",
    "        a += 1\n",
    "        \n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
