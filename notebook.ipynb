{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hummus - Community Based Recommendations**\n",
    "Notebook for the first project for the Machine Learning Complements course (CAC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils as ut\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import networkx as nx\n",
    "import os\n",
    "from networkx.algorithms.community import greedy_modularity_communities, girvan_newman, label_propagation_communities\n",
    "import matplotlib.pyplot as plt\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Dataset, Reader, KNNBasic, NormalPredictor, SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = True\n",
    "SAMPLES = 10000\n",
    "USE_SAMPLES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SAMPLES:\n",
    "    df_members = pd.read_csv('pp_members_sampled.csv')\n",
    "    df_recipes = pd.read_csv('pp_recipes_sampled.csv')\n",
    "    df_reviews = pd.read_csv('pp_reviews_sampled.csv')\n",
    "else:\n",
    "    df_members = pd.read_csv('pp_members.csv')#, nrows=SAMPLES)\n",
    "    df_recipes = pd.read_csv('pp_recipes.csv')#, nrows=SAMPLES)\n",
    "    df_reviews = pd.read_csv('pp_reviews.csv', nrows=SAMPLES)\n",
    "\n",
    "    df_members = df_members[df_members['member_id'].isin(df_reviews['member_id'])] # keep only members who have reviewed\n",
    "    df_recipes = df_recipes[df_recipes['recipe_id'].isin(df_reviews['recipe_id'])] # keep only recipes that have been reviewed\n",
    "    \n",
    "    # Save the sampled data\n",
    "    df_members.to_csv('pp_members_sampled.csv', index=False)\n",
    "    df_recipes.to_csv('pp_recipes_sampled.csv', index=False)\n",
    "    df_reviews.to_csv('pp_reviews_sampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observation - Members dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.initial_obs(df_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_members.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observation - Recipes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.initial_obs(df_recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observation - Reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.initial_obs(df_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot amount of reviews over rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.plot_reviews_rating(df_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot amount of users over amount of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.plot_num_users_num_reviews(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average rating for each recipe\n",
    "# Filter recipes with more than 20 reviews\n",
    "filtered_recipes = df_recipes[df_recipes['number_of_ratings'] > 20]\n",
    "\n",
    "# Sort recipes based on average rating\n",
    "top_rated_recipes = filtered_recipes.sort_values(by='average_rating', ascending=False).head(10)\n",
    "\n",
    "# Print the name and rating of the top-rated recipes as well as the number of reviews\n",
    "print('Top-Rated Recipes:')\n",
    "print('------------------')\n",
    "\n",
    "for index, recipe in top_rated_recipes.iterrows():\n",
    "    print(f\"{recipe['title']} (Recipe ID: {recipe['recipe_id']}) - Average Rating: {recipe['average_rating']:.2f} ({recipe['number_of_ratings']} reviews)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Preparation - Create the graph for network analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a graph with the members as nodes and the reviews as edges. The weight of the edges will be the number of reviews in common (to the same recipe with the same attitude) between the two members. This will allow us to use network analysis to find communities of members with similar tastes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will group the reviews by recipe and evaluations, so we can extract the members that have something in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group reviews by recipe and evaluation (>3, <=3)\n",
    "grouped_reviews = df_reviews.groupby(['recipe_id', df_reviews['rating'] > 3])\n",
    "\n",
    "# Create a dictionary to store relations between users\n",
    "user_relations = {}\n",
    "\n",
    "# Iterate through each group\n",
    "for (recipe_id, is_positive_rating), group in grouped_reviews:\n",
    "    # Extract user IDs for this recipe and evaluation\n",
    "    if VERBOSE: print(recipe_id, is_positive_rating, group['member_id'].unique())\n",
    "    user_ids = group['member_id'].unique()\n",
    "    user_ids.sort()\n",
    "    \n",
    "    # Update relations between users for this recipe\n",
    "    for i, user_id1 in enumerate(user_ids):\n",
    "        for user_id2 in user_ids[i+1:]:\n",
    "            # Check if there's an entry for this relation between users\n",
    "            if (user_id1, user_id2) not in user_relations:\n",
    "                if VERBOSE: print(f\"Creating new relation between {user_id1} and {user_id2}\")\n",
    "                user_relations[(user_id1, user_id2)] = 0\n",
    "            \n",
    "            # Increment the relation count between the users based on the evaluation\n",
    "            user_relations[(user_id1, user_id2)] += 1\n",
    "            if VERBOSE: print(f\"Relation between {user_id1} and {user_id2} has been incremented to {user_relations[(user_id1, user_id2)]}\")\n",
    "\n",
    "# Now user_relations contains relations between users\n",
    "if VERBOSE: print(\"Size of user_relations:\", len(user_relations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users with the same taste will have a high number in the relation, and users with different tastes will have a low number. Here are the most strong relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = sorted(user_relations.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Print the 10 most frequent key-value pairs\n",
    "for key, value in sorted_dict[:10]:\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the graph..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "vertex_indices = {}\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists('graph_file.graphml'):\n",
    "    # Load the graph from file\n",
    "    if VERBOSE: print(\"Loading graph from file\")\n",
    "    g = nx.read_graphml('graph_file.graphml')\n",
    "else:\n",
    "    if VERBOSE: print(\"Creating new graph\")\n",
    "    for (u,v), weight in user_relations.items():\n",
    "        g.add_edge(u, v, weight = weight)\n",
    "    nx.write_graphml(g, \"graph_file.graphml\")\n",
    "    \n",
    "# Find the largest connected component so we have a connected graph\n",
    "largest_component = max(nx.connected_components(g), key=len)\n",
    "g = g.subgraph(largest_component)\n",
    "\n",
    "if VERBOSE: print(g)\n",
    "nx.draw(g, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Network Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes:\", g.number_of_nodes())\n",
    "print(\"Number of edges:\", g.number_of_edges())\n",
    "print(\"Average degree:\", sum(dict(g.degree()).values()) / g.number_of_nodes())\n",
    "print(\"Graph density:\", nx.density(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph itself is very sparse as the density is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Law Distribution\n",
    "Here, we will investigate whether our network adheres to a power law distribution, which signifies a characteristic pattern in which a few nodes possess an exceptionally high number of connections, while the majority have only a few connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = sorted([d for n, d in g.degree()], reverse=True)\n",
    "degree_count = np.unique(degree_sequence, return_counts=True)\n",
    "\n",
    "# Plot degree distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(degree_count[0], degree_count[1], marker='o', color='b', alpha=0.5)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title(\"Degree Distribution\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our network does follow a power law distribution. However, there are some outliers that might appear because we're only looking at a portion of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Influencial Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll employ various statistical measures to extract insights about our data, particularly focusing on identifying influential users. To achieve this, we will compute different centrality metrics including degree centrality, betweenness centrality, eigenvector centrality, PageRank and closeness centrality for the top 10 users in each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user with high degree centrality likely reviews a large number of recipes. They may be very active in providing feedback on various recipes, indicating a strong engagement with the platform or community. They might have a significant influence on others in the network, potentially influencing their choices of recipes for others to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMOUNT_USERS = 10\n",
    "\n",
    "degree_centrality = nx.degree_centrality(g)\n",
    "degree_centrality = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "degree_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in degree_centrality])]\n",
    "degree_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closeness Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measure for finding the individuals who are best placed to influence the entire network most quickly, meaning the users that are \"close\" to all other users in the network in terms of the shortest paths between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closeness_centrality = nx.closeness_centrality(g, distance='weight')\n",
    "# closeness_centrality = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "# closeness_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in closeness_centrality])]\n",
    "# closeness_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measure shows which users who are ‘bridges’ between other users in a network, it's good to find the individuals who influence the flow around a system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#betweenness_centrality = nx.betweenness_centrality(g, weight= 'weight')\n",
    "#betweenness_centrality = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "#betweenness_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in betweenness_centrality])]\n",
    "#betweenness_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EigenVector Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigen_centrality = nx.eigenvector_centrality(g, weight='weight')\n",
    "# eigen_centrality = sorted(eigen_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "# eigen_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in eigen_centrality])]\n",
    "# eigen_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_rank = nx.pagerank(g, weight='weight')\n",
    "#page_rank = sorted(page_rank.items(), key=lambda x: x[1], reverse=True)\n",
    "#page_rank_members = df_members[df_members['member_id'].isin([int(x[0]) for x in page_rank])]\n",
    "#page_rank_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Detection\n",
    "In this part we will test different community detection algorithms and run some metrics to find out which one is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Louvain Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_communities = greedy_modularity_communities(g)\n",
    "for i, community in enumerate(louvain_communities):\n",
    "    print(f\"Community {i + 1}: {len(community)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Propagation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_prop_communities = list(label_propagation_communities(g))\n",
    "label_prop_communities = sorted(label_prop_communities, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "for i, community in enumerate(label_prop_communities):\n",
    "    print(f\"Community {i + 1}: {len(community)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Filtering\n",
    "Here we will be removing the communities with very few users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average number of users in a community\n",
    "average_users = sum([len(x) for x in louvain_communities]) / len(louvain_communities)\n",
    "print(\"Average Amount Users p/ Community: \", average_users)\n",
    "\n",
    "filtered_communities = [c for c in louvain_communities if len(c) >= average_users]\n",
    "for i, community in enumerate(filtered_communities):\n",
    "    print(f\"Community {i + 1}: {len(community)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_users = [int(user) for sublist in filtered_communities for user in sublist]\n",
    "\n",
    "filtered_members_df = df_members[df_members['member_id'].isin(filtered_users)]\n",
    "filtered_reviews_df = df_reviews[df_reviews['member_id'].isin(filtered_users)]\n",
    "filtered_recipes_df = df_recipes[df_recipes['recipe_id'].isin(filtered_reviews_df['recipe_id'])]\n",
    "\n",
    "print(\"Shape of Filtered Members:\", filtered_members_df.shape)\n",
    "print(\"Shape of Filtered Reviews:\", filtered_reviews_df.shape)\n",
    "print(\"Shape of Filtered Recipes\", filtered_recipes_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering (Applied @ each community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll be exploring recommender systems that help suggest items based on similarities between users or items. We'll dive into both user-based and item-based collaborative filtering methods. Our aim is to apply these techniques to different communities, assess how well they work for each, and then gauge their overall performance by averaging the errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will predict a user's preferences based on the preferences of similar users (users in the same community)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rmse, avg_mae = ut.collaborative_filtering(df_reviews, filtered_communities, 0.25, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\033[1m-----Overall Performance-----\\033[0m\")\n",
    "print(f\"\\033[1mAverage RMSE ->\\033[0m\", avg_rmse)\n",
    "print(f\"\\033[1mAverage MAE ->\\033[0m\", avg_mae)\n",
    "print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Item-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we will use a recommendation approach that predicts a user's preferences by examining similarities between items rather than users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rmse, avg_mae = ut.collaborative_filtering(df_reviews, filtered_communities, 0.25, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\033[1m-----Overall Performance-----\\033[0m\")\n",
    "print(f\"\\033[1mAverage RMSE ->\\033[0m\", avg_rmse)\n",
    "print(f\"\\033[1mAverage MAE ->\\033[0m\", avg_mae)\n",
    "print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will employ model-based collaborative filtering for personalized recommendations, contrasting with memory-based methods. Unlike memory-based approaches that directly compare user-item interactions, model-based methods utilize mathematical models to capture underlying patterns and relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rmse, avg_mae = ut.collaborative_filtering(df_reviews, filtered_communities, 0.25, False, 'SVD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\033[1m-----Overall Performance-----\\033[0m\")\n",
    "print(f\"\\033[1mAverage RMSE ->\\033[0m\", avg_rmse)\n",
    "print(f\"\\033[1mAverage MAE ->\\033[0m\", avg_mae)\n",
    "print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity model (Naive Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popularity model\n",
    "#Sort by \"average_rating\" and numeber_of_ratings > 30\n",
    "df_recipes = df_recipes[df_recipes['number_of_ratings'] > 30]\n",
    "df_recipes = df_recipes.sort_values(by='average_rating', ascending=False)\n",
    "\n",
    "# Get top N recommendations\n",
    "top_n_popularity = df_recipes.head(10)\n",
    "\n",
    "# Print the top N recommended items\n",
    "print(\"\\nTop Recommendations using Popularity Model:\")\n",
    "for index, recipe in top_n_popularity.iterrows():\n",
    "    print(f\"ID: {recipe['recipe_id']}, Title: {recipe['title']}, Average Rating: {recipe['average_rating']:.2f}, Number of Ratings: {recipe['number_of_ratings']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Step 2: Load the DataFrame into the Surprise Dataset\n",
    "data = Dataset.load_from_df(df_reviews[['member_id', 'recipe_id', 'rating']], reader)\n",
    "\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, trainset, testset):\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Recommender\n",
    "random_algo = NormalPredictor()\n",
    "rmse = evaluate_model(random_algo, trainset, testset)\n",
    "print(f\"RMSE for Random Recommender: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering (Applied @ whole data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory-Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubcf_algo = KNNBasic(sim_options={'user_based': True})\n",
    "rmse = evaluate_model(ubcf_algo, trainset, testset)\n",
    "print(f\"RMSE for User-Based Collaborative Filtering: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Item-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibcf_algo = KNNBasic(sim_options={'user_based': False})\n",
    "rmse = evaluate_model(ibcf_algo, trainset, testset)\n",
    "print(f\"RMSE for Item-Based Collaborative Filtering: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Based"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
