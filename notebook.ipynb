{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hummus - Community Based Recommendations**\n",
    "Notebook for the first project for the Machine Learning Complements course (CAC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils as ut\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import networkx as nx\n",
    "import os\n",
    "from networkx.algorithms.community import greedy_modularity_communities, girvan_newman, label_propagation_communities\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = True\n",
    "SAMPLES = 10000\n",
    "USE_SAMPLES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SAMPLES:\n",
    "    df_members = pd.read_csv('pp_members_sampled.csv')\n",
    "    df_recipes = pd.read_csv('pp_recipes_sampled.csv')\n",
    "    df_reviews = pd.read_csv('pp_reviews_sampled.csv')\n",
    "else:\n",
    "    df_members = pd.read_csv('pp_members.csv')#, nrows=SAMPLES)\n",
    "    df_recipes = pd.read_csv('pp_recipes.csv')#, nrows=SAMPLES)\n",
    "    df_reviews = pd.read_csv('pp_reviews.csv', nrows=SAMPLES)\n",
    "\n",
    "    df_members = df_members[df_members['member_id'].isin(df_reviews['member_id'])] # keep only members who have reviewed\n",
    "    df_recipes = df_recipes[df_recipes['recipe_id'].isin(df_reviews['recipe_id'])] # keep only recipes that have been reviewed\n",
    "    \n",
    "    # Save the sampled data\n",
    "    df_members.to_csv('pp_members_sampled.csv', index=False)\n",
    "    df_recipes.to_csv('pp_recipes_sampled.csv', index=False)\n",
    "    df_reviews.to_csv('pp_reviews_sampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observation - Members dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.initial_obs(df_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_members.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observation - Recipes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.initial_obs(df_recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Observation - Reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.initial_obs(df_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratings Distribution By User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratings_count = df_reviews.groupby('member_id')['rating'].count().clip(upper=50)\n",
    "\n",
    "# Plot the distribution of ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(ratings_count, bins=range(1, 15), color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Reviews')\n",
    "plt.xlabel('Number of Reviews')\n",
    "plt.ylabel('Number of Members')\n",
    "plt.xticks(range(1, 20))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average rating for each recipe\n",
    "# Filter recipes with more than 10 reviews\n",
    "filtered_recipes = df_recipes[df_recipes['number_of_ratings'] > 20]\n",
    "\n",
    "# Sort recipes based on average rating\n",
    "top_rated_recipes = filtered_recipes.sort_values(by='average_rating', ascending=False).head(10)\n",
    "\n",
    "# Print the name and rating of the top-rated recipes as well as the number of reviews\n",
    "print('Top-Rated Recipes:')\n",
    "print('------------------')\n",
    "\n",
    "for index, recipe in top_rated_recipes.iterrows():\n",
    "    print(f\"{recipe['title']} (Recipe ID: {recipe['recipe_id']}) - Average Rating: {recipe['average_rating']:.2f} ({recipe['number_of_ratings']} reviews)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Preparation - Create the graph for network analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a graph with the members as nodes and the reviews as edges. The weight of the edges will be the number of reviews in common (to the same recipe with the same attitude) between the two members. This will allow us to use network analysis to find communities of members with similar tastes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will group the reviews by recipe and evaluations, so we can extract the members that have something in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group reviews by recipe and evaluation (>3, <=3)\n",
    "grouped_reviews = df_reviews.groupby(['recipe_id', df_reviews['rating'] > 3])\n",
    "\n",
    "# Create a dictionary to store relations between users\n",
    "user_relations = {}\n",
    "\n",
    "# Iterate through each group\n",
    "for (recipe_id, is_positive_rating), group in grouped_reviews:\n",
    "    # Extract user IDs for this recipe and evaluation\n",
    "    if VERBOSE: print(recipe_id, is_positive_rating, group['member_id'].unique())\n",
    "    user_ids = group['member_id'].unique()\n",
    "    user_ids.sort()\n",
    "    \n",
    "    # Update relations between users for this recipe\n",
    "    for i, user_id1 in enumerate(user_ids):\n",
    "        for user_id2 in user_ids[i+1:]:\n",
    "            # Check if there's an entry for this relation between users\n",
    "            if (user_id1, user_id2) not in user_relations:\n",
    "                if VERBOSE: print(f\"Creating new relation between {user_id1} and {user_id2}\")\n",
    "                user_relations[(user_id1, user_id2)] = 0\n",
    "            \n",
    "            # Increment the relation count between the users based on the evaluation\n",
    "            user_relations[(user_id1, user_id2)] += 1\n",
    "            if VERBOSE: print(f\"Relation between {user_id1} and {user_id2} has been incremented to {user_relations[(user_id1, user_id2)]}\")\n",
    "\n",
    "# Now user_relations contains relations between users\n",
    "if VERBOSE: print(\"Size of user_relations:\", len(user_relations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users with the same taste will have a high number in the relation, and users with different tastes will have a low number. Here are the most strong relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = sorted(user_relations.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Print the 10 most frequent key-value pairs\n",
    "for key, value in sorted_dict[:10]:\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the graph..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "vertex_indices = {}\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists('graph_file.graphml'):\n",
    "    # Load the graph from file\n",
    "    if VERBOSE: print(\"Loading graph from file\")\n",
    "    g = nx.read_graphml('graph_file.graphml')\n",
    "else:\n",
    "    if VERBOSE: print(\"Creating new graph\")\n",
    "    for (u,v), weight in user_relations.items():\n",
    "        g.add_edge(u, v, weight = weight)\n",
    "    nx.write_graphml(g, \"graph_file.graphml\")\n",
    "    \n",
    "if VERBOSE: print(g)\n",
    "nx.draw(g, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Network Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes:\", g.number_of_nodes())\n",
    "print(\"Number of edges:\", g.number_of_edges())\n",
    "print(\"Average degree:\", sum(dict(g.degree()).values()) / g.number_of_nodes())\n",
    "print(\"Graph density:\", nx.density(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph itself is very sparse as the density is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Law Distribution\n",
    "Here, we will investigate whether our network adheres to a power law distribution, which signifies a characteristic pattern in which a few nodes possess an exceptionally high number of connections, while the majority have only a few connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = sorted([d for n, d in g.degree()], reverse=True)\n",
    "degree_count = np.unique(degree_sequence, return_counts=True)\n",
    "\n",
    "# Plot degree distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(degree_count[0], degree_count[1], marker='o', color='b', alpha=0.5)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title(\"Degree Distribution\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our network does follow a power law distribution. However, there are some outliers that might appear because we're only looking at a portion of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Influencial Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll employ various statistical measures to extract insights about our data, particularly focusing on identifying influential users. To achieve this, we will compute different centrality metrics including degree centrality, betweenness centrality, eigenvector centrality, PageRank and closeness centrality for the top 10 users in each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user with high degree centrality likely reviews a large number of recipes. They may be very active in providing feedback on various recipes, indicating a strong engagement with the platform or community. They might have a significant influence on others in the network, potentially influencing their choices of recipes for others to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMOUNT_USERS = 10\n",
    "\n",
    "degree_centrality = nx.degree_centrality(g)\n",
    "degree_centrality = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#degree_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in degree_centrality])]\n",
    "#degree_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closeness Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measure for finding the individuals who are best placed to influence the entire network most quickly, meaning the users that are \"close\" to all other users in the network in terms of the shortest paths between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness_centrality = nx.closeness_centrality(g)\n",
    "closeness_centrality = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "#closeness_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in closeness_centrality])]\n",
    "#closeness_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measure shows which users who are ‘bridges’ between other users in a network, it's good to find the individuals who influence the flow around a system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_centrality = nx.betweenness_centrality(g, weight= 'weight')\n",
    "betweenness_centrality = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "#betweenness_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in betweenness_centrality])]\n",
    "#betweenness_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EigenVector Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_centrality = nx.eigenvector_centrality(g, weight='weight')\n",
    "eigen_centrality = sorted(eigen_centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "#eigen_centrality_members = df_members[df_members['member_id'].isin([int(x[0]) for x in eigen_centrality])]\n",
    "#eigen_centrality_members.head(AMOUNT_USERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Detection\n",
    "In this part we will test different community detection algorithms and run some metrics to find out which one is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Louvain Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_communities = greedy_modularity_communities(g)\n",
    "for i, community in enumerate(louvain_communities):\n",
    "    print(f\"Community {i + 1}: {len(community)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Propagation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_prop_communities = list(label_propagation_communities(g))\n",
    "label_prop_communities = sorted(label_prop_communities, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "for i, community in enumerate(label_prop_communities):\n",
    "    print(f\"Community {i + 1}: {len(community)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Filtering\n",
    "Here we will be removing the communities with very few users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average number of users in a community\n",
    "average_users = sum([len(x) for x in louvain_communities]) / len(louvain_communities)\n",
    "print(\"Average Amount Users p/ Community: \", average_users)\n",
    "\n",
    "filtered_communities = [c for c in louvain_communities if len(c) >= average_users]\n",
    "for i, community in enumerate(filtered_communities):\n",
    "    print(f\"Community {i + 1}: {len(community)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Initialize a list to store information about each community's recommender system\n",
    "community_results = []\n",
    "\n",
    "\n",
    "for i, community in enumerate(filtered_communities):\n",
    "    community = [int(c) for c in community]\n",
    "    \n",
    "    # Filter reviews for users in this community\n",
    "    community_reviews = df_reviews[df_reviews['member_id'].isin(community)]\n",
    " \n",
    "    if len(community_reviews) > 0:\n",
    "      \n",
    "\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        data = Dataset.load_from_df(community_reviews[['member_id', 'recipe_id', 'rating']], reader)\n",
    "        trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "        model = KNNBasic(sim_options={'user_based': True})\n",
    "        model.fit(trainset)\n",
    "\n",
    "        predictions = model.test(testset)\n",
    "        rmse = accuracy.rmse(predictions)\n",
    "       \n",
    "\n",
    "        # Save information about this community's recommender system\n",
    "        community_results.append({\n",
    "            'community_id': i + 1,\n",
    "            'num_users': len(community),\n",
    "            'rmse': rmse\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Community {i + 1} has insufficient data for recommendations.\")\n",
    "#192799\n",
    "# Print summary information about each community's recommender system\n",
    "print(\"\\nSummary of Community Recommender Systems:\")\n",
    "for result in community_results:\n",
    "    print(f\"Community {result['community_id']}:\")\n",
    "    print(f\"  RMSE: {result['rmse']}\")\n",
    "\n",
    "total_rmse = sum(result['rmse'] for result in community_results)\n",
    "\n",
    "# Calculate the average RMSE\n",
    "average_rmse = total_rmse / len(community_results)\n",
    "\n",
    "print(f\"Average RMSE across all communities: {average_rmse}\")\n",
    "\n",
    "# MAE calculation\n",
    "mae_values = [result['rmse'] for result in community_results]\n",
    "average_mae = mean_absolute_error([0] * len(mae_values), mae_values)\n",
    "print(f\"Average MAE across all communities: {average_mae}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Retrieve User's Data\n",
    "user_id = 68526\n",
    "# Retrieve reviews for the target user\n",
    "user_reviews = df_reviews[df_reviews['member_id'] == user_id]\n",
    "\n",
    "# Prepare data for the target user\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_reviews[['member_id', 'recipe_id', 'rating']], reader)\n",
    "\n",
    "# Train the model using the entire dataset\n",
    "trainset = data.build_full_trainset()\n",
    "model = KNNBasic(sim_options={'user_based': True})\n",
    "model.fit(trainset)\n",
    "\n",
    "# Get items that the user hasn't rated\n",
    "user_unrated_items = trainset.build_anti_testset(fill=0)\n",
    "user_unrated_items = [(user_id, item_id, 0) for (user_id, item_id, _) in user_unrated_items]\n",
    "\n",
    "# Make predictions for unrated items\n",
    "predictions = model.test(user_unrated_items)\n",
    "\n",
    "# Sort predictions to get top N recommendations\n",
    "top_n_recommendations = sorted(predictions, key=lambda x: x.est, reverse=True)[:10]  # Change 10 to the desired number of recommendations\n",
    "\n",
    "# Print or return the top N recommended items\n",
    "print(\"Top Recommendations for User {}: \".format(user_id))\n",
    "for prediction in top_n_recommendations:\n",
    "    print(\"Item ID: {}, Estimated Rating: {}\".format(prediction.iid, prediction.est))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
